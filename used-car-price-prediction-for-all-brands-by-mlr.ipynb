{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This R environment comes with many helpful analytics packages installed\n# It is defined by the kaggle/rstats Docker image: https://github.com/kaggle/docker-rstats\n# For example, here's a helpful package to load\n\nlibrary(tidyverse) # metapackage of all tidyverse packages\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nlist.files(path = \"../input\")\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Table of Contents\n\n* [Introduction](#chapter1)\n* [Data Preparation](#chapter2)\n* [Modeling](#chapter3)\n    * [Model 1](#section_3_1)\n    * [Model 2](#section_3_2)\n    * [Model 3](#section_3_3)\n* [Model Evulation](#chapter4)\n* [Conclusion](#chapter5)","metadata":{}},{"cell_type":"markdown","source":"### Introduction <a class=\"anchor\" id=\"chapter1\"></a>\nIn this analysis, we would like to predict the price of used cars of 9 brands. We first combined the dataset from 9 brands, factorizing and grouping cetegorical variables and dealing with NA values. \nThen, we used the function called stepAIC which offers stepwise regression for selecting independent variables. We improved the model by log-transformation and removing outliers. Eventually, we reach a final version of the model that yields the R^2 of 0.854.","metadata":{}},{"cell_type":"markdown","source":"### Data Preparation <a class=\"anchor\" id=\"chapter2\"></a>","metadata":{}},{"cell_type":"code","source":"# library packages\nlibrary(dplyr)\nlibrary(lattice)\nlibrary(ggplot2)\nlibrary(GGally)\nlibrary(readr)\nlibrary(car)\nlibrary(MASS)\nlibrary(caret) \n# suppressPackageStartupMessages() ","metadata":{"execution":{"iopub.status.busy":"2021-11-03T07:35:29.877657Z","iopub.execute_input":"2021-11-03T07:35:29.879593Z","iopub.status.idle":"2021-11-03T07:35:29.911808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# importing csv files\naudi <- read_csv(\"../input/used-car-dataset-ford-and-mercedes/audi.csv\", show_col_types = FALSE)\nbmw <- read_csv(\"../input/used-car-dataset-ford-and-mercedes/bmw.csv\",show_col_types = FALSE)\nford <- read_csv(\"../input/used-car-dataset-ford-and-mercedes/ford.csv\", show_col_types = FALSE)\nhyundi <- read_csv(\"../input/used-car-dataset-ford-and-mercedes/hyundi.csv\", show_col_types = FALSE)\nmerc <- read_csv(\"../input/used-car-dataset-ford-and-mercedes/merc.csv\",show_col_types = FALSE)\nskoda <- read_csv(\"../input/used-car-dataset-ford-and-mercedes/skoda.csv\",show_col_types = FALSE)\ntoyota <- read_csv(\"../input/used-car-dataset-ford-and-mercedes/toyota.csv\",show_col_types = FALSE)\nvauxhall <- read_csv(\"../input/used-car-dataset-ford-and-mercedes/vauxhall.csv\",show_col_types = FALSE)\nvw <- read_csv(\"../input/used-car-dataset-ford-and-mercedes/vw.csv\",show_col_types = FALSE)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T06:14:55.034352Z","iopub.execute_input":"2021-11-03T06:14:55.036371Z","iopub.status.idle":"2021-11-03T06:14:55.494914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# combing dataset\n\ndf <- bind_rows(list(audi, bmw, ford, hyundi, merc, skoda, toyota, vauxhall, vw), .id=\"id\")\nsummary(df)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T06:14:55.498799Z","iopub.execute_input":"2021-11-03T06:14:55.500752Z","iopub.status.idle":"2021-11-03T06:14:55.704954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data preparing \n# assign the brand name to the combined dataframe\n\ndf <- df %>% mutate( brand = case_when(\n  id == 1 ~ \"audi\", \n  id == 2 ~ \"bmw\", \n  id == 3 ~ \"ford\",\n  id == 4 ~ \"hyundi\",\n  id == 5 ~ \"merc\",\n  id == 6 ~ \"skoda\",\n  id == 7 ~ \"toyota\",\n  id == 8 ~ \"vauxhall\",\n  id == 9 ~ \"vw\"))","metadata":{"execution":{"iopub.status.busy":"2021-11-03T06:14:55.707529Z","iopub.execute_input":"2021-11-03T06:14:55.708975Z","iopub.status.idle":"2021-11-03T06:14:56.083389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# regrouping the categorical variables \n\ndf <- df %>% mutate(engineLevel = case_when (\n  engineSize < 1 ~ \"0\",\n  engineSize >= 1 & engineSize < 2 ~ \"1\",\n  engineSize >= 2 & engineSize < 3 ~ \"2\",\n  engineSize >= 3 & engineSize < 4 ~ \"3\",\n  engineSize >= 4 & engineSize < 5 ~ \"4\",\n  engineSize >= 5  ~ \"5_plus\"\n))\n\ndf <- df %>% mutate(fuelType_re = case_when (\n  fuelType == \"Electric\" | fuelType == \"Other\" ~ \"Elec_other\",\n  TRUE ~ fuelType\n))","metadata":{"execution":{"iopub.status.busy":"2021-11-03T06:14:57.755096Z","iopub.execute_input":"2021-11-03T06:14:57.756618Z","iopub.status.idle":"2021-11-03T06:14:57.833021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# replacing the missing tax value with mean of tax\ndf <- df %>% mutate(tax= replace(tax, is.na(tax), mean(tax, na.rm=TRUE)))","metadata":{"execution":{"iopub.status.busy":"2021-11-03T06:15:01.880889Z","iopub.execute_input":"2021-11-03T06:15:01.88252Z","iopub.status.idle":"2021-11-03T06:15:01.902413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# change the variable to factor \nsummary(as.factor(df$fuelType_re))\ncols = c(\"transmission\", \"fuelType_re\",\"brand\", \"engineLevel\")\ndf[cols] <- lapply(df[cols], as.factor)\nlapply(df[cols], levels)\n\n# droping the unjustifiable data and check the sume of missing data in each column\ndf <- df[df$transmission != \"Other\",]\ndf <- df[df$year <= \"2020\", ]\ncolSums(is.na(df))\nsummary(df)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T06:15:03.873869Z","iopub.execute_input":"2021-11-03T06:15:03.875649Z","iopub.status.idle":"2021-11-03T06:15:04.390209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Spliting the dataset into training and testing data\ntrain.size <- 0.8\nset.seed(99)\ntrain.index <- sample.int(length(df$price), round(length(df$price)*train.size))\ntrains <- df[train.index, ]\ntests <- df[-train.index, ]\nsummary(df)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T06:15:06.892977Z","iopub.execute_input":"2021-11-03T06:15:06.89478Z","iopub.status.idle":"2021-11-03T06:15:07.014518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Modeling <a class=\"anchor\" id=\"chapter3\"></a>","metadata":{}},{"cell_type":"markdown","source":"### First Model <a class=\"anchor\" id=\"section_3_1\"></a>","metadata":{}},{"cell_type":"code","source":"# We use stepwise selection for varaible selection:\nmfull <- lm(price ~ engineSize + year + transmission + brand + mileage + tax + fuelType_re + mpg, data =trains)\n\n# the stepAIC function can successively add and drop predictors to find a model that has lower AIC and higher adjusted R2\nstep_mfull <- stepAIC(mfull, direction=\"both\")\nsummary(step_mfull)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T06:15:10.040848Z","iopub.execute_input":"2021-11-03T06:15:10.042711Z","iopub.status.idle":"2021-11-03T06:15:11.752767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We did not drop any variables after running the stepAIC function, but the adjusted r-squared is only 0.7668.","metadata":{}},{"cell_type":"code","source":"#Checking regression assumption by diagonstic plots\noptions(repr.plot.width = 14, repr.plot.height = 14)\npar(mfrow=c(2,2))\nplot(step_mfull)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T06:16:28.000967Z","iopub.execute_input":"2021-11-03T06:16:28.002642Z","iopub.status.idle":"2021-11-03T06:16:41.668381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Results of model 1:**\n\nThe diagnostic plots show us that some influential points affect our prediction.\nNext, we used Cooks' distance will be used for eliminate the outliers. \n\nThe first plot (residuals v.s. fitted values) is a scatterplot between residuals and predicted values. There are some unusual points on the top left corner, and the points are not distributed evenly.\n\nThe second plot (normal Q-Q) is a normal probability plot. It will give a straight line if the errors are distributed normally, but the points at the head and tail deviate severely from the straight line. \n\nThe third plot (scale-location) is a scatterplot showing the spread of residuals. Like the first plot, there are some unusual points at the corner, and the points are not distributed evenly.\n\nThe fourth plot (residuals vs leverage) help us find the inferential points. Luckily we do not have points lying outside the Cook's distance.\n\nIn the following part, we will do the log transformation on price to reduce skewness.","metadata":{}},{"cell_type":"markdown","source":"### Second Model <a class=\"anchor\" id=\"section_3_2\"></a>","metadata":{}},{"cell_type":"code","source":"# We tried to improve the model by log transformation\n# log transformation on price to fit the normality assumption\ndf$log_price <- log10(df$price)\n\ntrain.index <- sample.int(length(df$price), round(length(df$price)*train.size))\ntrains <- df[train.index, ]\ntests <- df[-train.index, ]\n\noptions(repr.plot.width = 14, repr.plot.height = 7)\npar(mfrow=c(1,2))\nqqnorm(df$price, main=\"Normal Q-Q Plot of Price Before Log Transformation\");qqline(df$price)\nqqnorm(df$log_price, main=\"Normal Q-Q Plot of Price After Log Transformation\");qqline(df$log_price)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T07:28:26.661826Z","iopub.execute_input":"2021-11-03T07:28:26.663552Z","iopub.status.idle":"2021-11-03T07:28:35.270421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We use stepwise selection for varaible selection:\nmfull2 <- lm(log_price ~ engineSize + year + transmission + brand + mileage + tax + fuelType_re + mpg, data =trains)\n\n# the stepAIC function can successively add and drop predictors to find a model that has lower AIC and higher adjusted R2\nstep_mfull2 <- stepAIC(mfull2, direction=\"both\")\nsummary(step_mfull2)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T07:28:38.664108Z","iopub.execute_input":"2021-11-03T07:28:38.665603Z","iopub.status.idle":"2021-11-03T07:28:39.583941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"options(repr.plot.width = 14, repr.plot.height = 14)\npar(mfrow=c(2,2))\nplot(step_mfull2)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T06:20:15.302766Z","iopub.execute_input":"2021-11-03T06:20:15.304607Z","iopub.status.idle":"2021-11-03T06:20:28.454442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Results of model 2:**\n\nThe adjusted r-squared increased from 0.7668 to 0.8754.\n\nAccording to the Residuals vs Leverage graph, all the diagnostic plots improved, but there are some influential points. ","metadata":{}},{"cell_type":"markdown","source":"### Third Model <a class=\"anchor\" id=\"section_3_3\"></a>","metadata":{}},{"cell_type":"code","source":"# We tried to improved the model by removing outliers\n# We use the general rule of thumb to remove the points that with a Cook's D of more than 3 times the mean,\ncooksD1 <- cooks.distance(step_mfull2)\ninf_1 <- cooksD1[(cooksD1 > (3 * mean(cooksD1, na.rm = TRUE)))] \n\ninf_name1 <- names(inf_1)\noutliers1 <- trains[inf_name1,]\ntrains_after <- trains %>% anti_join(outliers1)\n\nnew_mfull <- lm(log_price ~ engineSize + year + transmission + brand + mileage + tax + fuelType_re + mpg, data = trains_after)\n\nstep_mfull3 <- stepAIC(new_mfull, direction=\"both\")\nsummary(step_mfull3)\n\noptions(repr.plot.width = 14, repr.plot.height = 14)\npar(mfrow=c(2,2))\nplot(step_mfull3)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T07:31:32.361871Z","iopub.execute_input":"2021-11-03T07:31:32.363987Z","iopub.status.idle":"2021-11-03T07:31:46.535928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Results of model 3:**\n\nAfter removing outliers, the adjusted r-squared increased a little from 0.8754 to 0.8957.\n\nWe can see that the points are spread randomly on the graphs from the Residual vs Fitted plot and Scale-Location plot.\nThe qq plot shows that most residuals follow the straight line, and the deviated points are gone.\nAlso, for the Residuals-Leverage plot, no more points are lying outside the dashed line. ","metadata":{}},{"cell_type":"markdown","source":"### Model Evaluation <a class=\"anchor\" id=\"chapter4\"></a>","metadata":{}},{"cell_type":"code","source":"# evaluating the model by the test data\ntests$pred_price1  <- predict(step_mfull, newdata=tests, select=c(price, engineSize, year, \n                        transmission, brand, mileage, tax, fuelType_re, mpg))\n\ntests$pred_price_log2  <- predict(step_mfull2, newdata=tests, select=c(log_price, engineSize, year, \n                        transmission, brand, mileage, tax, fuelType_re, mpg))\n\ntests$pred_price_log3 <- predict(step_mfull3, newdata=tests, select=c(log_price, engineSize, year, \n                        transmission, brand, mileage, tax, fuelType_re, mpg))\n\n\ntests$pred_price2 <- 10^(tests$pred_price_log2)\ntests$pred_price3 <- 10^(tests$pred_price_log3)\n\ndata.frame(R2_m1 = R2(tests$pred_price1, tests$price),\n           RMSE_m1 = RMSE(tests$pred_price1, tests$price),\n           MAE_m1 = MAE(tests$pred_price1, tests$price),\n           R2_m2 = R2(tests$pred_price2, tests$price),\n           RMSE_m2 = RMSE(tests$pred_price2, tests$price),\n           MAE_m2 = MAE(tests$pred_price2, tests$price),\n           R2_m3 = R2(tests$pred_price3, tests$price),\n           RMSE_m3 = RMSE(tests$pred_price3, tests$price),\n           MAE_m3 = MAE(tests$pred_price3, tests$price)\n          )","metadata":{"execution":{"iopub.status.busy":"2021-11-03T07:33:44.519495Z","iopub.execute_input":"2021-11-03T07:33:44.5214Z","iopub.status.idle":"2021-11-03T07:33:44.639564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we check the collinearity by vif function in car package:\nvif(step_mfull3)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T07:14:01.451218Z","iopub.execute_input":"2021-11-03T07:14:01.452842Z","iopub.status.idle":"2021-11-03T07:14:01.510874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since all the GVIF scores are lower than 5, we don't have a collinear problem in this model.","metadata":{}},{"cell_type":"markdown","source":"### Conclusion <a class=\"anchor\" id=\"chapter5\"></a>","metadata":{}},{"cell_type":"markdown","source":"The third model has a R^2 score of 85.4%, and the RMSE and MAE are lower than others. Thus we will use the third model for price prediction.  ","metadata":{}},{"cell_type":"code","source":"# predicting car price\npred_try1 <- data.frame(year=2019, transmission = \"Automatic\", mileage = 20000, mileage=1000,\n                        fuelType_re = \"Hybrid\", tax=100, mpg = 100, engineLevel = \"2\", engineSize=4, brand=\"bmw\")\n\n10^(predict(step_mfull3, newdata=pred_try1))","metadata":{"execution":{"iopub.status.busy":"2021-11-03T07:12:44.888399Z","iopub.execute_input":"2021-11-03T07:12:44.890037Z","iopub.status.idle":"2021-11-03T07:12:44.912532Z"},"trusted":true},"execution_count":null,"outputs":[]}]}